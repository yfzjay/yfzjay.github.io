---
layout: post
title: 'HashMap'
date: 2020-03-21
author: yza
color: rgb(255,210,32)
cover: '../assets/java.jpg'
tags: java java基础
typora-copy-images-to: ..\assets\image
---



##   什么是HashMap？

![img]({{site.baseurl}}/assets/image/640.webp)





![img]({{site.baseurl}}/assets/image/640.webp)





![img]({{site.baseurl}}/assets/image/640.webp)





![img]({{site.baseurl}}/assets/image/640.webp)





————————————





![img]({{site.baseurl}}/assets/image/640.webp)





![img]({{site.baseurl}}/assets/image/640.webp)





![img]({{site.baseurl}}/assets/image/640.webp)





![img]({{site.baseurl}}/assets/image/640-1584760541605.webp)





![img]({{site.baseurl}}/assets/image/640-1584760541615.webp)





![img]({{site.baseurl}}/assets/image/640-1584760541624.webp)





众所周知，HashMap是一个用于存储Key-Value键值对的集合，每一个键值对也叫做**Entry**。这些个键值对（Entry）分散存储在一个数组当中，这个数组就是HashMap的主干。



HashMap数组每一个元素的初始值都是Null。





![img]({{site.baseurl}}/assets/image/640-1584760541667.webp)





对于HashMap，我们最常使用的是两个方法：**Get** 和 **Put**。





#### **1.Put方法的原理**



调用Put方法的时候发生了什么呢？



比如调用 hashMap.put("apple", 0) ，插入一个Key为“apple"的元素。这时候我们需要利用一个哈希函数来确定Entry的插入位置（index）：



**index = Hash（“apple”）**



假定最后计算出的index是2，那么结果如下：





![img]({{site.baseurl}}/assets/image/640.png)





但是，因为HashMap的长度是有限的，当插入的Entry越来越多时，再完美的Hash函数也难免会出现index冲突的情况。比如下面这样：





![img]({{site.baseurl}}/assets/image/640.png)





这时候该怎么办呢？我们可以利用**链表**来解决。



HashMap数组的每一个元素不止是一个Entry对象，也是一个链表的头节点。每一个Entry对象通过Next指针指向它的下一个Entry节点。当新来的Entry映射到冲突的数组位置时，只需要插入到对应的链表即可：



![img]({{site.baseurl}}/assets/image/640.png)





需要注意的是，新来的Entry节点插入链表时，使用的是“头插法”。至于为什么不插入链表尾部，后面会有解释。



#### **2.Get方法的原理**

使用Get方法根据Key来查找Value的时候，发生了什么呢？



首先会把输入的Key做一次Hash映射，得到对应的index：



**index = Hash（“apple”）**



由于刚才所说的Hash冲突，同一个位置有可能匹配到多个Entry，这时候就需要顺着对应链表的头节点，一个一个向下来查找。假设我们要查找的Key是“apple”：



![img]({{site.baseurl}}/assets/image/640-1584760541675.webp)





第一步，我们查看的是头节点Entry6，Entry6的Key是banana，显然不是我们要找的结果。



第二步，我们查看的是Next节点Entry1，Entry1的Key是apple，正是我们要找的结果。



之所以把Entry6放在头节点，是因为HashMap的发明者认为，**后插入的Entry被查找的可能性更大**。

![img]({{site.baseurl}}/assets/image/640-1584760600331.webp)





![img]({{site.baseurl}}/assets/image/640-1584760600332.webp)





![img]({{site.baseurl}}/assets/image/640-1584760600333.webp)


![img]({{site.baseurl}}/assets/image/640-1584760631637.webp)





![img]({{site.baseurl}}/assets/image/640-1584760631644.webp)





![img]({{site.baseurl}}/assets/image/640-1584760652894.webp)

![img]({{site.baseurl}}/assets/image/640-1584760783868.webp)





![img]({{site.baseurl}}/assets/image/640-1584760783873.webp)





![img]({{site.baseurl}}/assets/image/640-1584760783883.webp)





![img]({{site.baseurl}}/assets/image/640-1584760783895.webp)





![img]({{site.baseurl}}/assets/image/640-1584760783898.webp)





之前说过，从Key映射到HashMap数组的对应位置，会用到一个Hash函数：



**index = Hash（“apple”）**



如何实现一个尽量均匀分布的Hash函数呢？我们通过利用Key的HashCode值来做某种运算。



![img]({{site.baseurl}}/assets/image/640-1584760783912.webp)





**index = HashCode（Key） % Length ?**





![img]({{site.baseurl}}/assets/image/640-1584760783924.webp)





如何进行位运算呢？有如下的公式（Length是HashMap的长度）：



**index = HashCode（Key） & （Length- 1）** 



下面我们以值为“book”的Key来演示整个过程：



1.计算book的hashcode，结果为十进制的3029737，二进制的101110001110101110 1001。



2.假定HashMap长度是默认的16，计算Length-1的结果为十进制的15，二进制的1111。



3.把以上两个结果做**与运算**，101110001110101110 1001 & 1111 = 1001，十进制是9，所以 index=9。



可以说，Hash算法最终得到的index结果，完全取决于Key的Hashcode值的最后几位。







![img]({{site.baseurl}}/assets/image/640-1584760783929.webp)





![img]({{site.baseurl}}/assets/image/640-1584760783939.webp)





假设HashMap的长度是10，重复刚才的运算步骤：





![img]({{site.baseurl}}/assets/image/640-1584760783947.webp)





单独看这个结果，表面上并没有问题。我们再来尝试一个新的HashCode 101110001110101110 **1011** ：





![img]({{site.baseurl}}/assets/image/640-1584760783972.png)





让我们再换一个HashCode 101110001110101110 **1111** 试试 ：





![img]({{site.baseurl}}/assets/image/640-1584760783960.webp)



是的，虽然HashCode的倒数第二第三位从0变成了1，但是运算的结果都是1001。也就是说，当HashMap长度为10的时候，有些index结果的出现几率会更大，而有些index结果永远不会出现（比如0111）！



这样，显然不符合Hash算法均匀分布的原则。



反观长度16或者其他2的幂，Length-1的值是所有二进制位全为1，这种情况下，index的结果等同于HashCode后几位的值。只要输入的HashCode本身分布均匀，Hash算法的结果就是均匀的。

## HashMap的高并发问题

![img]({{site.baseurl}}/assets/image/640-1584760783966.webp)



![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424484-bba70c0a01465c9.jpeg)







![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424484-0dada4a2185396f.jpeg)





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424484-13de2ee20a63bd4.jpeg)





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424484-13de2ee20a63bd4-1.jpeg)





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424485-c5b270a18dbd168.jpeg)





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424485-a24a7fcf512a6a1.jpeg)





HashMap的容量是有限的。当经过多次元素插入，使得HashMap达到一定饱和度时，Key映射位置发生冲突的几率会逐渐提高。



这时候，HashMap需要扩展它的长度，也就是进行**Resize**。







![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424485-2a37ad2fb153307.png)





影响发生Resize的因素有两个：

**
**

**1.Capacity**

HashMap的当前长度。上一期曾经说过，HashMap的长度是2的幂。



**2.LoadFactor**

HashMap负载因子，默认值为0.75f。





衡量HashMap是否进行Resize的条件如下：

**
**

**HashMap.Size  >= Capacity * LoadFactor**





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424485-390e0b9b6d8167b.jpeg)





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424485-5215bc65517a307.jpeg)





**1.扩容**

创建一个新的Entry空数组，长度是原数组的2倍。







**2.ReHash**

遍历原Entry数组，把所有的Entry重新Hash到新数组。为什么要重新Hash呢？因为长度扩大以后，Hash的规则也随之改变。



让我们回顾一下Hash公式：

**index = HashCode（****Key****） & （****Length** **– 1）** 



当原数组长度为8时，Hash运算是和111B做与运算；新数组长度为16，Hash运算是和1111B做与运算。Hash结果显然不同。





**Resize前的HashMap：**

**
**



![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424486-09c94b54aea1290.png)





**Resize后的HashMap：**

**
**



![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424486-d0a8ade4d7465f5.png)





**ReHash的Java代码如下：**

**
**

```
/**
 * Transfers all entries from current table to newTable.
 */
void transfer(Entry[] newTable, boolean rehash) {
    int newCapacity = newTable.length;
    for (Entry<K,V> e : table) {
        while(null != e) {
            Entry<K,V> next = e.next;
            if (rehash) {
                e.hash = null == e.key ? 0 : hash(e.key);
            }
            int i = indexFor(e.hash, newCapacity);
            e.next = newTable[i];
            newTable[i] = e;
            e = next;
        }
    }
}
```



![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424486-645ebfd02dc39e2.jpeg)





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424486-a308d1f16e6c764.jpeg)





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424487-8d77fd2708d4e23.jpeg)





**注意：下面的内容十分烧脑，请小伙伴们坐稳扶好。**





假设一个HashMap已经到了Resize的临界点。此时有两个线程A和B，在同一时刻对HashMap进行Put操作：







![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424487-563ed681a60f872.png)





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424487-8d77fd2708d4e23.png)





此时达到Resize条件，两个线程各自进行Rezie的第一步，也就是扩容：





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424488-9eed90a2714461b.png)





这时候，两个线程都走到了ReHash的步骤。让我们回顾一下ReHash的代码：



![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424488-88345f29a46aefd.png)



假如此时线程B遍历到Entry3对象，刚执行完红框里的这行代码，线程就被挂起。对于线程B来说：



**e = Entry3**

**next = Entry2**

**
**

这时候线程A畅通无阻地进行着Rehash，当ReHash完成后，结果如下（图中的e和next，代表线程B的两个引用）：





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424488-88345f29a46aefd-1.png)





直到这一步，看起来没什么毛病。接下来线程B恢复，继续执行属于它自己的ReHash。线程B刚才的状态是：





**e = Entry3**

**next = Entry2**

**
**



![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424489-0ce457966482ef8.png)

当执行到上面这一行时，显然 i = 3，因为刚才线程A对于Entry3的hash结果也是3。





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424489-a038ecc86314559.png)



我们继续执行到这两行，Entry3放入了线程B的数组下标为3的位置，并且**e指向了Entry2**。此时e和next的指向如下：



**e = Entry2**

**next = Entry2**



整体情况如图所示：







![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424489-7b0c5690d364cde.png)





接着是新一轮循环，又执行到红框内的代码行：



![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424490-70860a5b905594b.png)



**e = Entry2**

**next = Entry3**



整体情况如图所示：





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424490-70860a5b905594b-1.png)







接下来执行下面的三行，用头插法把Entry2插入到了线程B的数组的头结点：





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424490-a5533d3036d1555.png)





整体情况如图所示：



![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424491-c0c6cb15f20ccf4.png)





第三次循环开始，又执行到红框的代码：



![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424491-139e79dbfe86dca.png)

**
**

**e = Entry3**

**next = Entry3.next = null**

**
**

最后一步，当我们执行下面这一行的时候，见证奇迹的时刻来临了：





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424491-69db984b925cfba.png)



**newTable[i] = \**Entry2\****

**e = Entry3**

***\**\*Entry2.next = Entry3\*\**\***

**Entry3.next = Entry2**

**
**

**链表出现了环形！**

**
**

整体情况如图所示：





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424491-d40fa642005fe3a.png)





此时，问题还没有直接产生。当调用Get查找一个不存在的Key，而这个Key的Hash结果恰好等于3的时候，由于位置3带有环形链表，所以程序将会进入**死循环**！



这种情况，不禁让人联想到一道经典的面试题：

[漫画算法：如何判断链表有环？]({{site.baseurl}}/2020/03/21/链表有环问题.html)



![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424492-d9e025a7c750955.jpeg)





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424492-45ba377a9129a97.jpeg)







![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424492-7c8dc8fc80df7f2.jpeg)





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424493-9bf9d6cf122efcd.jpeg)





![漫画：高并发下的HashMap]({{site.baseurl}}/assets/image/1572424493-1724628feda87da.jpeg)





**1.Hashmap在插入元素过多的时候需要进行Resize，Resize的条件是**

**HashMap.Size  >= Capacity * LoadFactor。**

***

**2.Hashmap的Resize包含扩容和ReHash两个步骤，ReHash在并发的情况下可能会形成链表环。**
