---
layout: post
title: 'hadoop一些随笔总结'
date: 2020-02-27
author: yza
color: rgb(255,210,32)
cover: '../assets/bigdata.jpg'
tags: 大数据 hadoop
typora-copy-images-to: ..\assets\image
---

### hadoop优缺点

缺点：速度慢（但多个节点并发就不慢了），不支持随机修改（支持追加），不支持并发写。

优点：高容错（多副本机制）。适合处理大数据：数据规模大（PB级别），文件数量规模大（百万规模）。

### hdfs随笔

1.块不能太大：用mapreduce处理太慢。也不能太小：寻址时间太长。

2.hdfs一般至少6个节点，一个namenode,一个secondarynamenode,一个resourcemanager,三个节点放datanode+nodemanager。

3.2nn的用处是辅助namenode持久化。nn元数据希望从Fs_image恢复（速度快），同时希望修改后向editlog写。想到可以从Fs_image恢复后再执行editlog。但是有两个缺陷：1是向editlog写的时候就不允许再向nn写。2.editlog越来越大，占空间的同时，内存恢复也很慢。这样就由2nn去定期把editlog整合到fsimage上，editlog用新的即可。具体步骤见讲义。

4.环境变量$PATH中的目录定义过后，就可以在命令行直接运行里面的脚本。任何用户都有/bin这个环境变量在$PATH中，但每个用户都有自己的/home/bin，因此自己制作脚本时（如分发脚本），应把脚本放在/bin下。更新配置文件/etc/profile后，记得source，以生效环境变量。

5.safemode发生在nn启动时。nn启动完成如下动作：（1）dn给nn块列表，nn生成块->主机的映射信息。（2）加载Fs_Image和editlog，恢复带最新状态。Fs_image是一个映像，某一时刻的内存中的元数据状态，像游戏中的一个存档。启动完成后结束safemode。safemode过程中不能对nn写入。之后每一小时，dn给nn一次块列表。且每3秒有一次心跳传给nn，并带着nn的指令回到dn。超时TimeOut=2*heart_recheck+10*heart_interval，当超过TimeOut时，nn认定该dn死亡，报错。可以手动设置recheck和interval以改timeout。

6.退役节点时一定用黑名单机制，被退役节点会把数据备份到其他节点上。白名单只用在不同集群之间。

#### 更多知识见hdfs讲义

### mapreduce随笔

1.有三次排序：从环形缓冲区溢出到磁盘之间，做一个二次排序，先对分区排，分区内部按key排，排序方法时快排。第二次是maptask完成后，对每个溢出到磁盘的文件进行归并排序（还是各分区归并）。第三次是不同maptask得到的k-v汇总到reducetask后做一次归并。

2.combiner发生在第一，二次排序之后，将key值整合。作用是减小map阶段的输出，减小I/O消耗。需要注意的是combiner在逻辑上不能改变最终输出结果，二是输入输出泛型应与map输出，reduce输入都相同。

3.如果分组规则需要和排序规则不同，需要用group，需要注意的是排序规则必须包含分组规则，也就是排序规则比分组规则粒度更小。比如：找每个id下最大value。排序规则是先按id排，id一样的按value降序排。分组规则是按id排。

4.mr各个节点之间，节点内的各控件之间，都用序列化后的对象传递数据。接收方备好空对象以反序列化。在reducer方法中，首先准备两个对象key，value,开始赋值为迭代器所指第一个，而后通过values.next()指针下移，移到第二个。再下移时，就将第二个k-v对反序列化（如果不为空），同时下移后会检查当前所指是否和上一个是同一组，若不是，直接结束迭代。若reducer方法结束，直接指到下一组上。

5.mapper方法把k-v输出到环形缓冲区。环形缓冲区可在任何一个位置开始写入，一边写k-v，另一边同时写索引。查询k-v可直接查索引。当缓冲区容量达到80%（可自行设置，总容量大小100M也可设置），开始2次排序。但交换的是索引，这样就加快了速度，较小cpu利用。排序后还可能经过combiner后落盘，这边落着盘，那边可以从剩余的20%继续写，等不到20%被写满，80%就被腾空，可以继续写入了，这样就能无限写。

6.通过context(job)可以获得相应切片，进而获得path，进而获得filename,filedir等。还可以获得configuration,进而获得FileSystem,进而开流。还能从con获得想要的配置信息。如输入输出路径等。

7.shuffle流程图：

![img]({{site.baseurl}}/assets/image/wps1.png)

![img]({{site.baseurl}}/assets/image/wps2.png)

![img]({{site.baseurl}}/assets/image/wps3.png)

#### 更多知识见mapreduce讲义和git代码